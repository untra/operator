{
  "$schema": "./issuetype_schema.json",
  "key": "ASSESS",
  "name": "Project Assessment",
  "description": "Analyze project structure and generate project-context.json and catalog-info.yaml",
  "mode": "autonomous",
  "glyph": "~",
  "color": "magenta",
  "project_required": true,
  "agent_prompt": "Review this project to create an agent for project assessment. The agent analyzes project structure, detects the project Kind from file patterns (using the 25-Kind taxonomy), identifies commands/entry points/environment variables, and generates both project-context.json (for AI agents) and catalog-info.yaml (for Backstage). Output ONLY the agent system prompt.",
  "fields": [
    {
      "name": "id",
      "description": "Unique ticket identifier",
      "type": "string",
      "required": true,
      "auto": "id",
      "display_order": 0,
      "user_editable": false
    },
    {
      "name": "summary",
      "description": "Assessment description",
      "type": "string",
      "required": true,
      "default": "",
      "placeholder": "Assess project for Backstage catalog",
      "max_length": 120,
      "display_order": 1
    },
    {
      "name": "kind_override",
      "description": "Override detected Kind (optional)",
      "type": "string",
      "required": false,
      "default": "",
      "placeholder": "e.g., microservice, infrastructure",
      "display_order": 2
    }
  ],
  "steps": [
    {
      "name": "analyze",
      "display_name": "Analyzing",
      "outputs": ["report"],
      "jsonSchemaFile": "src/templates/project_analysis.schema.json",
      "prompt": "Analyze the project structure and output structured JSON conforming to the schema:\n\n1. **Kind Detection**: Match file patterns against the 25-Kind taxonomy:\n   - Foundation: infrastructure, identity-access, config-policy, monorepo-meta\n   - Standards: design-system, software-library, proto-sdk, blueprint, security-tooling, compliance-audit\n   - Engines: ml-model, data-etl, microservice, api-gateway, ui-frontend, internal-tool\n   - Ecosystem: build-tool, e2e-test, docs-site, playbook, cli-devtool\n   - Noncurrent: reference-example, experiment-sandbox, archival-fork, test-data-fixtures\n\n2. **Languages/Frameworks/Databases**: Detect from manifest files (package.json, Cargo.toml, requirements.txt, go.mod), imports, and file extensions.\n\n3. **Commands**: Extract from:\n   - package.json scripts (start, dev, test, build, lint)\n   - Makefile targets\n   - Cargo.toml [[bin]] sections\n   - Scripts in bin/ or scripts/\n\n4. **Entry Points**: Identify key files:\n   - binary_entry: src/main.rs, index.js, main.py\n   - library_entry: src/lib.rs, lib/index.js\n   - config: config/*.toml, .env.example\n   - routes: src/routes.rs, routes/*.ts\n   - main_component: src/App.tsx, src/App.vue\n\n5. **Environment Variables**: Scan .env.example, docker-compose.yml, config files for required env vars.\n\nIf kind_override is set, use that instead of auto-detection.",
      "allowed_tools": ["Read", "Glob", "Grep"],
      "next_step": "generate"
    },
    {
      "name": "generate",
      "display_name": "Generating",
      "outputs": ["code"],
      "prompt": "Generate output files from the analysis JSON:\n\n1. **Write `project-context.json`** (for AI agents):\n   - Save the complete structured analysis JSON to project root\n   - This is the primary output for AI consumption\n\n2. **Write `catalog-info.yaml`** (for Backstage UI):\n   ```yaml\n   apiVersion: backstage.io/v1alpha1\n   kind: Component\n   metadata:\n     name: {{ project }}\n     description: <from CLAUDE.md or package.json>\n     annotations:\n       backstage.io/techdocs-ref: dir:.\n     tags:\n       - <primary-language>\n       - <primary-framework>\n   spec:\n     type: <detected-kind-backstage-type>\n     lifecycle: production\n     owner: <from config or 'platform-team'>\n   ```\n\n3. **Document assessment** in `.tickets/assessments/{{ id }}.md`:\n   - Kind detected with confidence score\n   - Key technologies found\n   - Commands available\n   - Entry points identified",
      "allowed_tools": ["Read", "Write", "Edit"],
      "review_type": "plan",
      "on_reject": {
        "goto_step": "analyze",
        "prompt": "Re-analyze the project with feedback: {{ rejection_reason }}"
      }
    }
  ]
}
